{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Лабораторная работа №4. Различные подходы к решению задачи детектирования объектов\n",
    "1. Загрузить набор данных «Номера тормозных башмаков» (data_sl.zip)\n",
    "2. Провести предварительный анализ набора данных, провести оценку качества набора данных, указать возможные пути улучшения набора данных\n",
    "3. Ознакомиться с материалами теории алгоритма фонтанного преобразования (например, https://newdisser.ru/_avtoreferats/01005395270.pdf, \n",
    "https://cyberleninka.ru/article/n/modelirovanie-protsessa-identifikatsii-graficheskihobektov/viewer)\n",
    "4. Разработать модуль распознавания номера башмака при помощи фонтанного преобразования\n",
    "5. Ознакомиться с материалами по архитектуре YOLOv11 (https://github.com/ultralytics/ultralytics, https://docs.ultralytics.com/quickstart/)\n",
    "6. Загрузить предобученную модель YOLOv11 для решения задачи распознавания цифр как подвида задачи детектирования объектов/сегментации изображений\n",
    "7. Разработать модуль распознавания номера башмака при помощи YOLOv11\n",
    "8. Провести сравнительный анализ эффективности методов фонтанного преобразования и модели на архитектуре YOLOv11 для решения задачи распознавания \n",
    "номера тормозного башмака.\n",
    "9. Сделать сравнительную таблицу с достоинствами, недостатками каждого алгоритма, особое внимание уделить точности и скорости работ\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 14.444%\n"
     ]
    }
   ],
   "source": [
    "#Фонтанное преобразование 1 датасет\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Путь к исполняемому файлу Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Tesseract\\tesseract.exe\"\n",
    "image_dir = 'Numbers_yolov11/train/images' # Путь к изображениям\n",
    "label_dir = 'Numbers_yolov11/train/labels' # Путь к меткам изображений\n",
    "\n",
    "def load_images_and_annotations(image_dir, label_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Загрузка изображения\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append((filename, img))\n",
    "            \n",
    "            # Загрузка аннотации\n",
    "            label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [line.strip().split() for line in f.readlines()]\n",
    "                annotations.append((filename, labels))\n",
    "            else:\n",
    "                annotations.append((filename, []))\n",
    "    return images, annotations\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразование в оттенки серого\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Инвертирование цветов\n",
    "    inverted = cv2.bitwise_not(gray)\n",
    "    # Применение адаптивной бинаризации\n",
    "    thresh = cv2.adaptiveThreshold(inverted, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def extract_digits(img):\n",
    "    # Настройка конфигурации Tesseract для распознавания только цифр\n",
    "    custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789'\n",
    "    result = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return result.strip()\n",
    "\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    average_precision = average_precision_score(true_labels, pred_labels, average='macro')\n",
    "    return precision, recall, average_precision\n",
    "\n",
    "#Загрузка изображений и меток\n",
    "images, annotations = load_images_and_annotations(image_dir, label_dir)\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "with open('results1.txt', 'w', encoding='utf-8') as f:\n",
    "    for (filename, img), (_, labels) in zip(images, annotations):\n",
    "        #print(f\"Файл: {filename}\")\n",
    "        # Предварительная обработка изображения\n",
    "        processed_img = preprocess_image(img)\n",
    "        # Извлечение предсказанных цифр\n",
    "        pred_digits = extract_digits(processed_img)\n",
    "        #print(f\"Распознанные метки: {pred_digits}\")\n",
    "        # Получение истинных меток из аннотаций\n",
    "        true_digits = [label[0] for label in labels]\n",
    "        #print(f\"Метки: {true_digits}\")\n",
    "        # Запись результатов в файл\n",
    "        # Формат: filename | распознанные метки | истинные метки\n",
    "        f.write(f\"Файл: {filename}\\n\")\n",
    "        f.write(f\"Распознанные метки: {''.join(pred_digits)}\\n\")\n",
    "        f.write(f\"Метки: {''.join(true_digits)}\\n\")\n",
    "        f.write(\"\\n\")  # разделитель между записями    \n",
    "\n",
    "        # Преобразование в бинарный формат для вычисления метрик\n",
    "        true_labels = [1 if str(i) in true_digits else 0 for i in range(10)]\n",
    "        pred_labels = [1 if str(i) in pred_digits else 0 for i in range(10)]       \n",
    "        all_true_labels.append(true_labels)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "\n",
    "\n",
    "# Вычисление точности\n",
    "precision = precision_score(all_true_labels, all_pred_labels, average='macro', zero_division=0) \n",
    "print(f\"Точность: {precision*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанные цифры: 7492\n",
      "404\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def recognize_digits(image_path):\n",
    "    # Загружаем изображение\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Преобразуем изображение в оттенки серого\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Применяем пороговое значение для улучшения контраста\n",
    "    _, thresh_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Распознаем текст (цифры) на изображении\n",
    "    custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
    "    recognized_text = pytesseract.image_to_string(thresh_image, config=custom_config)\n",
    "\n",
    "    return recognized_text.strip()\n",
    "\n",
    "image_name = 'test1.jpg'\n",
    "result = recognize_digits(image_name)\n",
    "print(f'Распознанные цифры: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанные цифры: 01234\n",
      "16789\n"
     ]
    }
   ],
   "source": [
    "image_name2 = 'test2.jpg'\n",
    "result2 = recognize_digits(image_name2)\n",
    "print(f'Распознанные цифры: {result2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 25.230%\n"
     ]
    }
   ],
   "source": [
    "#Фонтанное преобразование 2 датасет\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Путь к исполняемому файлу Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Tesseract\\tesseract.exe\"\n",
    "image_dir = 'Yolo8v2/train/images' # Путь к изображениям\n",
    "label_dir = 'Yolo8v2/train/labels' # Путь к меткам изображений\n",
    "\n",
    "def load_images_and_annotations(image_dir, label_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Загрузка изображения\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append((filename, img))\n",
    "            \n",
    "            # Загрузка аннотации\n",
    "            label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [line.strip().split() for line in f.readlines()]\n",
    "                annotations.append((filename, labels))\n",
    "            else:\n",
    "                annotations.append((filename, []))\n",
    "    return images, annotations\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразование в оттенки серого\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Инвертирование цветов\n",
    "    inverted = cv2.bitwise_not(gray)\n",
    "    # Применение адаптивной бинаризации\n",
    "    thresh = cv2.adaptiveThreshold(inverted, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def extract_digits(img):\n",
    "    # Настройка конфигурации Tesseract для распознавания только цифр\n",
    "    custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789'\n",
    "    result = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return result.strip()\n",
    "\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    average_precision = average_precision_score(true_labels, pred_labels, average='macro')\n",
    "    return precision, recall, average_precision\n",
    "\n",
    "#Загрузка изображений и меток\n",
    "images, annotations = load_images_and_annotations(image_dir, label_dir)\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "with open('results2.txt', 'w', encoding='utf-8') as f:\n",
    "    for (filename, img), (_, labels) in zip(images, annotations):\n",
    "        #print(f\"Файл: {filename}\")\n",
    "        # Предварительная обработка изображения\n",
    "        processed_img = preprocess_image(img)\n",
    "        # Извлечение предсказанных цифр\n",
    "        pred_digits = extract_digits(processed_img)\n",
    "        #print(f\"Распознанные метки: {pred_digits}\")\n",
    "        # Получение истинных меток из аннотаций\n",
    "        true_digits = [label[0] for label in labels]\n",
    "        #print(f\"Метки: {true_digits}\")\n",
    "        # Запись результатов в файл\n",
    "        # Формат: filename | распознанные метки | истинные метки\n",
    "        f.write(f\"Файл: {filename}\\n\")\n",
    "        f.write(f\"Распознанные метки: {''.join(pred_digits)}\\n\")\n",
    "        f.write(f\"Метки: {''.join(true_digits)}\\n\")\n",
    "        f.write(\"\\n\")  # разделитель между записями    \n",
    "\n",
    "        # Преобразование в бинарный формат для вычисления метрик\n",
    "        true_labels = [1 if str(i) in true_digits else 0 for i in range(10)]\n",
    "        pred_labels = [1 if str(i) in pred_digits else 0 for i in range(10)]       \n",
    "        all_true_labels.append(true_labels)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "\n",
    "\n",
    "# Вычисление точности\n",
    "precision = precision_score(all_true_labels, all_pred_labels, average='macro', zero_division=0) \n",
    "print(f\"Точность: {precision*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Numbers_yolov8/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection1-11s, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection1-11s, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    822504  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,430,888 parameters, 9,430,872 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 41.114.1 MB/s, size: 24.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\train\\labels.cache... 97 images, 1 backgrounds, 0 corrupt: 100%|██████████| 97/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 43.84.2 MB/s, size: 23.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection1-11s\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005859375000000001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection1-11s\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G       1.98      5.766      1.648        134        640: 100%|██████████| 4/4 [00:48<00:00, 12.10s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74    0.00589     0.0408    0.00638     0.0035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.581      4.618      1.389         87        640: 100%|██████████| 4/4 [00:44<00:00, 11.21s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.163     0.0985     0.0293     0.0151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.514      4.134      1.297        114        640: 100%|██████████| 4/4 [00:45<00:00, 11.32s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74     0.0206      0.109     0.0295     0.0168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.045 hours.\n",
      "Optimizer stripped from runs\\detect\\detection1-11s\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\detection1-11s\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\detection1-11s\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "YOLO11s summary (fused): 100 layers, 9,415,896 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74     0.0206      0.109      0.029     0.0158\n",
      "                     0         14         14    0.00909     0.0714    0.00602    0.00421\n",
      "                     1          4          4          0          0          0          0\n",
      "                     4         10         13     0.0308      0.154     0.0179    0.00857\n",
      "                     5         17         28      0.104      0.536      0.179     0.0979\n",
      "                     6          6          6          0          0          0          0\n",
      "                     7          2          4          0          0          0          0\n",
      "                     8          5          5          0          0          0          0\n",
      "Speed: 1.5ms preprocess, 133.4ms inference, 0.0ms loss, 143.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection1-11s\u001b[0m\n",
      "YOLO11s summary (fused): 100 layers, 9,415,896 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 360.776.3 MB/s, size: 25.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74     0.0206      0.109      0.029     0.0158\n",
      "                     0         14         14    0.00909     0.0714    0.00602    0.00421\n",
      "                     1          4          4          0          0          0          0\n",
      "                     4         10         13     0.0308      0.154     0.0179    0.00857\n",
      "                     5         17         28      0.104      0.536      0.179     0.0979\n",
      "                     6          6          6          0          0          0          0\n",
      "                     7          2          4          0          0          0          0\n",
      "                     8          5          5          0          0          0          0\n",
      "Speed: 0.8ms preprocess, 121.3ms inference, 0.0ms loss, 146.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection1-11s2\u001b[0m\n",
      "mAP для боксов: 0.015810894998429095\n",
      "\n",
      "image 1/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650106_jpg.rf.848e68240ae6864df221714f16ef0e97.jpg: 640x640 (no detections), 271.0ms\n",
      "image 2/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501101_jpg.rf.7a6800606789a61bcce0d56539c74f06.jpg: 640x640 (no detections), 263.1ms\n",
      "image 3/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501140_jpg.rf.9c17a64d40f589564c9c5063a7687209.jpg: 640x640 (no detections), 231.7ms\n",
      "image 4/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501180_jpg.rf.76e96c21ff790091132bdb4e9fd10f87.jpg: 640x640 (no detections), 187.0ms\n",
      "image 5/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501185_jpg.rf.dad6b6ed4d5acad105e7333a23dae357.jpg: 640x640 (no detections), 207.9ms\n",
      "image 6/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650119_jpg.rf.76d27479e4a19c2e6ff554af6812b1fc.jpg: 640x640 2 0s, 1 5, 249.1ms\n",
      "image 7/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501284_jpg.rf.98f8ec758cec188b451d9ca2da4998d2.jpg: 640x640 1 5, 244.7ms\n",
      "image 8/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501314_jpg.rf.b4d85baee790a4f125aff81e6f5df2d2.jpg: 640x640 2 0s, 222.8ms\n",
      "image 9/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501315_jpg.rf.2eecb9c1bf1dde7a38fdc61cb15b39c5.jpg: 640x640 1 0, 212.4ms\n",
      "image 10/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650360_jpg.rf.6c2784f868d7cf61e57292b58663719a.jpg: 640x640 (no detections), 219.9ms\n",
      "image 11/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265039_jpg.rf.a764b90158df06b18cecf408d8048593.jpg: 640x640 (no detections), 243.4ms\n",
      "image 12/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265045_jpg.rf.b1937d2593bd7757d811cd0303e98522.jpg: 640x640 (no detections), 234.1ms\n",
      "image 13/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650487_jpg.rf.06dff3c9266ce4ab893d090c625bf3cc.jpg: 640x640 (no detections), 237.5ms\n",
      "image 14/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650489_jpg.rf.50a27e2a4120b0013c7495dd53aac03b.jpg: 640x640 (no detections), 204.4ms\n",
      "image 15/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650528_jpg.rf.aae060939dd52b4e4e722ba3cde8d293.jpg: 640x640 (no detections), 191.1ms\n",
      "image 16/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650548_jpg.rf.4add2d80922c08a01ded690f2402b096.jpg: 640x640 (no detections), 215.0ms\n",
      "image 17/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650663_jpg.rf.023d2a900669e0230df1bc6e26d0d312.jpg: 640x640 (no detections), 198.0ms\n",
      "image 18/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650747_jpg.rf.2c7642d61ba0da23697abc5a3325591a.jpg: 640x640 2 0s, 195.2ms\n",
      "image 19/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650756_jpg.rf.e565ffb368b31a58be165875483e0e89.jpg: 640x640 3 0s, 205.6ms\n",
      "image 20/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650765_jpg.rf.755619bccfd1e172ecce0af948ddc670.jpg: 640x640 3 0s, 190.4ms\n",
      "image 21/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650799_jpg.rf.1d9a8fc1cfa736c0bffd235ff46069d2.jpg: 640x640 (no detections), 198.8ms\n",
      "Speed: 3.1ms preprocess, 220.1ms inference, 1.4ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection1-11s3\u001b[0m\n",
      "7 labels saved to runs\\detect\\detection1-11s3\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO11 - 1 датасет\n",
    "import os\n",
    "# Заставляем использовать python-реализацию NMS через переопределение\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Сохраняем оригинальную реализацию NMS, которая работает на CPU\n",
    "_original_nms = torchvision.ops.nms\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    # Переносим данные на CPU, выполняем NMS и возвращаем результат на исходном устройстве\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "# Переопределяем torchvision.ops.nms на нашу CPU-версию\n",
    "torchvision.ops.nms = custom_nms\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Определение устройства: 'cuda' для GPU, иначе 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 1. Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolo11s.pt')\n",
    "model.to(device)  # Перевод модели на GPU, если доступен\n",
    "    \n",
    "    # 2. Обучение модели на GPU\n",
    "model.train(data='Numbers_yolov8/data.yaml', epochs=3, imgsz=640, batch=25, name='detection1-11s', device=device)\n",
    "    \n",
    "    # 3. Оценка модели на GPU\n",
    "metrics = model.val(device=device)\n",
    "print(f\"mAP для боксов: {metrics.box.map}\")\n",
    "    # print(f\"mAP для масок: {metrics.seg.map}\") - для сегментации, у меня ошибки выдаёт\n",
    "    \n",
    "    # 4. Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Numbers_yolov8/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Yolo8v2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection2-11m, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection2-11m, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  3                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  4                  -1  1    103360  ultralytics.nn.modules.block.C3k2            [128, 256, 1, False, 0.25]    \n",
      "  5                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      "  6                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1380352  ultralytics.nn.modules.block.C3k2            [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1    990976  ultralytics.nn.modules.block.C2PSA           [512, 512, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    443776  ultralytics.nn.modules.block.C3k2            [768, 256, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1    127680  ultralytics.nn.modules.block.C3k2            [512, 128, 1, False]          \n",
      " 17                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    345472  ultralytics.nn.modules.block.C3k2            [384, 256, 1, False]          \n",
      " 20                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1   1511424  ultralytics.nn.modules.block.C3k2            [768, 512, 1, True]           \n",
      " 23        [16, 19, 22]  1    822504  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "YOLO11s summary: 181 layers, 9,430,888 parameters, 9,430,872 gradients, 21.6 GFLOPs\n",
      "\n",
      "Transferred 493/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.40.3 ms, read: 58.38.5 MB/s, size: 28.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\train\\labels.cache... 309 images, 6 backgrounds, 0 corrupt: 100%|██████████| 309/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.30.2 ms, read: 49.011.2 MB/s, size: 19.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\valid\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection2-11m\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005859375000000001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection2-11m\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      2.605       4.95      2.476         55        640: 100%|██████████| 13/13 [02:25<00:00, 11.20s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77     0.0384     0.0395     0.0254     0.0157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.879      3.268      1.917         58        640: 100%|██████████| 13/13 [02:21<00:00, 10.85s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77     0.0535      0.136       0.08      0.035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.675      2.681      1.772         43        640: 100%|██████████| 13/13 [02:22<00:00, 10.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.176      0.219      0.169     0.0811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.126 hours.\n",
      "Optimizer stripped from runs\\detect\\detection2-11m\\weights\\last.pt, 19.2MB\n",
      "Optimizer stripped from runs\\detect\\detection2-11m\\weights\\best.pt, 19.2MB\n",
      "\n",
      "Validating runs\\detect\\detection2-11m\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "YOLO11s summary (fused): 100 layers, 9,415,896 parameters, 0 gradients, 21.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.175      0.219      0.169     0.0813\n",
      "                     0         15         17      0.129      0.176     0.0841     0.0475\n",
      "                     1          1          1          0          0          0          0\n",
      "                     4         10         16      0.788        0.5      0.631      0.295\n",
      "                     5         17         28      0.247      0.429      0.267      0.155\n",
      "                     6          6          7      0.058      0.429      0.201     0.0714\n",
      "                     7          3          4          0          0          0          0\n",
      "                     8          4          4          0          0          0          0\n",
      "Speed: 1.8ms preprocess, 132.9ms inference, 0.0ms loss, 145.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection2-11m\u001b[0m\n",
      "YOLO11s summary (fused): 100 layers, 9,415,896 parameters, 0 gradients, 21.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 236.158.7 MB/s, size: 21.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\valid\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.175      0.219      0.169     0.0813\n",
      "                     0         15         17      0.129      0.176     0.0841     0.0475\n",
      "                     1          1          1          0          0          0          0\n",
      "                     4         10         16      0.788        0.5      0.631      0.295\n",
      "                     5         17         28      0.247      0.429      0.267      0.155\n",
      "                     6          6          7      0.058      0.429      0.201     0.0714\n",
      "                     7          3          4          0          0          0          0\n",
      "                     8          4          4          0          0          0          0\n",
      "Speed: 1.1ms preprocess, 122.2ms inference, 0.0ms loss, 147.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection2-11m2\u001b[0m\n",
      "mAP для боксов: 0.08125379563111207\n",
      "\n",
      "image 1/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-1-_jpg.rf.d154cf900b4af2ce90b3c042b574c73c.jpg: 640x640 (no detections), 348.1ms\n",
      "image 2/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-100-_jpg.rf.8fc2e358992dda97dba4bf0e6a3a7b73.jpg: 640x640 3 0s, 2 5s, 1 6, 228.8ms\n",
      "image 3/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-116-_jpg.rf.76036d085131891b401a684d36e575e3.jpg: 640x640 2 5s, 1 6, 247.5ms\n",
      "image 4/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-121-_jpg.rf.0dc7b2cfe053e32782450d1a6720dfc3.jpg: 640x640 6 5s, 4 6s, 219.0ms\n",
      "image 5/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-125-_jpg.rf.94e483e69f932c2b03382e7ee9beaa15.jpg: 640x640 7 5s, 1 6, 197.2ms\n",
      "image 6/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-126-_jpg.rf.2b4156b788f206fda9c071b48f23603b.jpg: 640x640 4 5s, 1 6, 183.8ms\n",
      "image 7/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-128-_jpg.rf.01caedc7c86d693ea337d14a6054129a.jpg: 640x640 1 0, 7 5s, 2 6s, 227.4ms\n",
      "image 8/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-135-_jpg.rf.828c5cad3fcdba69655cd71621b953c3.jpg: 640x640 1 0, 1 5, 1 6, 244.2ms\n",
      "image 9/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-2-_jpg.rf.98ad04d69beacf3097a187ad77fa17fa.jpg: 640x640 1 0, 1 6, 290.4ms\n",
      "image 10/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-24-_jpg.rf.4cef0ff39c6ec7ba06b3298680cc6b28.jpg: 640x640 3 6s, 268.2ms\n",
      "image 11/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-30-_jpg.rf.3e5ee15db4dfb8985c6d2f9aa159e436.jpg: 640x640 1 6, 264.7ms\n",
      "image 12/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-31-_jpg.rf.097db28ac72fa2d268f48241987ff206.jpg: 640x640 1 0, 1 5, 248.6ms\n",
      "image 13/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-36-_jpg.rf.28455017f1359ec3d574e28ea916e701.jpg: 640x640 3 0s, 1 5, 1 6, 232.0ms\n",
      "image 14/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-46-_jpg.rf.8b40e60695629603d63df1888b47197f.jpg: 640x640 1 0, 2 5s, 1 6, 226.4ms\n",
      "image 15/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-50-_jpg.rf.9b814d0c40cddc47d0d027f5591d502f.jpg: 640x640 (no detections), 254.6ms\n",
      "image 16/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-56-_jpg.rf.0a6fcd77acb4d066adeac0bf29577ca2.jpg: 640x640 1 0, 2 6s, 304.3ms\n",
      "image 17/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-64-_jpg.rf.9af280aa66e985ea785f74b39110f3cb.jpg: 640x640 1 5, 1 6, 278.3ms\n",
      "image 18/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-68-_jpg.rf.b277cd334905e7d0e013e3421f9934fc.jpg: 640x640 3 0s, 1 5, 2 6s, 214.7ms\n",
      "image 19/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-7-_jpg.rf.96fae53a9c0f4de217a0d291242759a9.jpg: 640x640 2 0s, 2 6s, 247.1ms\n",
      "image 20/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-75-_jpg.rf.9f3eb21200832944140a89af96419630.jpg: 640x640 1 0, 3 6s, 256.9ms\n",
      "image 21/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-78-_jpg.rf.04a0fcd99c99b1196a452662d6c6d5e1.jpg: 640x640 1 5, 4 6s, 279.7ms\n",
      "image 22/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-8-_jpg.rf.3bfff7de7a35d6f72b9a82fb3ec02ae9.jpg: 640x640 3 0s, 1 6, 291.1ms\n",
      "Speed: 3.6ms preprocess, 252.4ms inference, 1.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection2-11m3\u001b[0m\n",
      "20 labels saved to runs\\detect\\detection2-11m3\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO11 - 2 датасет\n",
    "import os\n",
    "# Заставляем использовать python-реализацию NMS через переопределение\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Сохраняем оригинальную реализацию NMS, которая работает на CPU\n",
    "_original_nms = torchvision.ops.nms\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    # Переносим данные на CPU, выполняем NMS и возвращаем результат на исходном устройстве\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "# Переопределяем torchvision.ops.nms на нашу CPU-версию\n",
    "torchvision.ops.nms = custom_nms\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Определение устройства: 'cuda' для GPU, иначе 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 1. Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolo11s.pt')\n",
    "model.to(device)  # Перевод модели на GPU, если доступен\n",
    "    \n",
    "    # 2. Обучение модели на GPU\n",
    "model.train(data='Yolo8v2/data.yaml', epochs=3, imgsz=640, batch=25, name='detection2-11s', device=device)\n",
    "    \n",
    "    # 3. Оценка модели на GPU\n",
    "metrics = model.val(device=device)\n",
    "print(f\"mAP для боксов: {metrics.box.map}\")\n",
    "    # print(f\"mAP для масок: {metrics.seg.map}\") - для сегментации, у меня ошибки выдаёт\n",
    "    \n",
    "    # 4. Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Yolo8v2/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Numbers_yolov8/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection1-8s, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection1-8s, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,138,696 parameters, 11,138,680 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 56.211.5 MB/s, size: 24.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\train\\labels.cache... 97 images, 1 backgrounds, 0 corrupt: 100%|██████████| 97/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 52.36.1 MB/s, size: 23.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection1-8s\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005859375000000001), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection1-8s\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      2.027      8.476      1.656        134        640: 100%|██████████| 4/4 [00:44<00:00, 11.24s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74    0.00807     0.0458    0.00496    0.00279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.819      5.582       1.48         87        640: 100%|██████████| 4/4 [00:44<00:00, 11.03s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:07<00:00,  7.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74     0.0124     0.0102    0.00986    0.00614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.686      4.544      1.406        114        640: 100%|██████████| 4/4 [00:43<00:00, 10.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.041     0.0322     0.0338     0.0154\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.043 hours.\n",
      "Optimizer stripped from runs\\detect\\detection1-8s\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\detection1-8s\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\detection1-8s\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 72 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.150s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74     0.0376     0.0322     0.0288     0.0114\n",
      "                     0         14         14          0          0          0          0\n",
      "                     1          4          4          0          0          0          0\n",
      "                     4         10         13      0.222      0.154      0.145     0.0345\n",
      "                     5         17         28     0.0408     0.0714     0.0563      0.045\n",
      "                     6          6          6          0          0          0          0\n",
      "                     7          2          4          0          0          0          0\n",
      "                     8          5          5          0          0          0          0\n",
      "Speed: 1.3ms preprocess, 143.0ms inference, 0.0ms loss, 146.1ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection1-8s\u001b[0m\n",
      "\n",
      "image 1/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650106_jpg.rf.848e68240ae6864df221714f16ef0e97.jpg: 640x640 1 7, 206.5ms\n",
      "image 2/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501101_jpg.rf.7a6800606789a61bcce0d56539c74f06.jpg: 640x640 (no detections), 243.7ms\n",
      "image 3/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501140_jpg.rf.9c17a64d40f589564c9c5063a7687209.jpg: 640x640 (no detections), 191.2ms\n",
      "image 4/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501180_jpg.rf.76e96c21ff790091132bdb4e9fd10f87.jpg: 640x640 (no detections), 191.0ms\n",
      "image 5/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501185_jpg.rf.dad6b6ed4d5acad105e7333a23dae357.jpg: 640x640 3 0s, 247.7ms\n",
      "image 6/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650119_jpg.rf.76d27479e4a19c2e6ff554af6812b1fc.jpg: 640x640 (no detections), 226.4ms\n",
      "image 7/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501284_jpg.rf.98f8ec758cec188b451d9ca2da4998d2.jpg: 640x640 1 7, 252.2ms\n",
      "image 8/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501314_jpg.rf.b4d85baee790a4f125aff81e6f5df2d2.jpg: 640x640 (no detections), 309.5ms\n",
      "image 9/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501315_jpg.rf.2eecb9c1bf1dde7a38fdc61cb15b39c5.jpg: 640x640 (no detections), 253.1ms\n",
      "image 10/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650360_jpg.rf.6c2784f868d7cf61e57292b58663719a.jpg: 640x640 1 0, 235.7ms\n",
      "image 11/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265039_jpg.rf.a764b90158df06b18cecf408d8048593.jpg: 640x640 (no detections), 251.6ms\n",
      "image 12/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265045_jpg.rf.b1937d2593bd7757d811cd0303e98522.jpg: 640x640 1 9, 230.2ms\n",
      "image 13/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650487_jpg.rf.06dff3c9266ce4ab893d090c625bf3cc.jpg: 640x640 (no detections), 242.6ms\n",
      "image 14/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650489_jpg.rf.50a27e2a4120b0013c7495dd53aac03b.jpg: 640x640 7 7s, 233.9ms\n",
      "image 15/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650528_jpg.rf.aae060939dd52b4e4e722ba3cde8d293.jpg: 640x640 2 0s, 255.1ms\n",
      "image 16/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650548_jpg.rf.4add2d80922c08a01ded690f2402b096.jpg: 640x640 1 0, 239.2ms\n",
      "image 17/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650663_jpg.rf.023d2a900669e0230df1bc6e26d0d312.jpg: 640x640 (no detections), 253.7ms\n",
      "image 18/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650747_jpg.rf.2c7642d61ba0da23697abc5a3325591a.jpg: 640x640 1 7, 239.2ms\n",
      "image 19/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650756_jpg.rf.e565ffb368b31a58be165875483e0e89.jpg: 640x640 1 5, 1 7, 2 9s, 219.3ms\n",
      "image 20/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650765_jpg.rf.755619bccfd1e172ecce0af948ddc670.jpg: 640x640 2 9s, 249.8ms\n",
      "image 21/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650799_jpg.rf.1d9a8fc1cfa736c0bffd235ff46069d2.jpg: 640x640 (no detections), 234.0ms\n",
      "Speed: 3.0ms preprocess, 238.4ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection1-8s2\u001b[0m\n",
      "11 labels saved to runs\\detect\\detection1-8s2\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO8 1 датасет\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "_original_nms = torchvision.ops.nms\n",
    "torchvision.ops.nms = custom_nms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "# Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.to(device)\n",
    "    \n",
    "# Обучение модели \n",
    "model.train(data='Numbers_yolov8/data.yaml', epochs=3, imgsz=640, batch=25, name='detection1-8s', device=device)\n",
    "      \n",
    "# Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Numbers_yolov8/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Yolo8v2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection2-8s, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection2-8s, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
      "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
      "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
      "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
      "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
      "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
      " 22        [15, 18, 21]  1   2119144  ultralytics.nn.modules.head.Detect           [8, [128, 256, 512]]          \n",
      "Model summary: 129 layers, 11,138,696 parameters, 11,138,680 gradients, 28.7 GFLOPs\n",
      "\n",
      "Transferred 349/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 404.2116.6 MB/s, size: 28.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\train\\labels.cache... 309 images, 6 backgrounds, 0 corrupt: 100%|██████████| 309/309 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 323.977.2 MB/s, size: 19.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\valid\\labels.cache... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection2-8s\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005859375000000001), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection2-8s\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      2.856      5.879      2.668         55        640: 100%|██████████| 13/13 [02:22<00:00, 10.95s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95):   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING NMS time limit 3.100s exceeded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:06<00:00,  6.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77     0.0291      0.014    0.00949    0.00499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      2.087       3.39      2.083         58        640: 100%|██████████| 13/13 [02:22<00:00, 10.97s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:05<00:00,  5.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.619      0.183      0.196     0.0944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.801      2.721      1.923         43        640: 100%|██████████| 13/13 [02:21<00:00, 10.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.247      0.508      0.349      0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.124 hours.\n",
      "Optimizer stripped from runs\\detect\\detection2-8s\\weights\\last.pt, 22.5MB\n",
      "Optimizer stripped from runs\\detect\\detection2-8s\\weights\\best.pt, 22.5MB\n",
      "\n",
      "Validating runs\\detect\\detection2-8s\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 72 layers, 11,128,680 parameters, 0 gradients, 28.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:04<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         22         77      0.464      0.503      0.349      0.196\n",
      "                     0         15         17      0.143      0.647      0.574      0.299\n",
      "                     1          1          1     0.0696          1     0.0711     0.0355\n",
      "                     4         10         16      0.496      0.625      0.507      0.239\n",
      "                     5         17         28      0.371      0.571      0.564      0.333\n",
      "                     6          6          7      0.237      0.429      0.191     0.0805\n",
      "                     7          3          4          1          0          0          0\n",
      "                     8          4          4      0.929       0.25      0.538      0.381\n",
      "Speed: 1.8ms preprocess, 146.0ms inference, 0.0ms loss, 31.9ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection2-8s\u001b[0m\n",
      "\n",
      "image 1/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-1-_jpg.rf.d154cf900b4af2ce90b3c042b574c73c.jpg: 640x640 2 0s, 1 5, 239.8ms\n",
      "image 2/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-100-_jpg.rf.8fc2e358992dda97dba4bf0e6a3a7b73.jpg: 640x640 2 0s, 2 5s, 1 6, 212.3ms\n",
      "image 3/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-116-_jpg.rf.76036d085131891b401a684d36e575e3.jpg: 640x640 1 5, 224.9ms\n",
      "image 4/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-121-_jpg.rf.0dc7b2cfe053e32782450d1a6720dfc3.jpg: 640x640 3 0s, 1 4, 193.5ms\n",
      "image 5/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-125-_jpg.rf.94e483e69f932c2b03382e7ee9beaa15.jpg: 640x640 1 4, 4 5s, 215.3ms\n",
      "image 6/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-126-_jpg.rf.2b4156b788f206fda9c071b48f23603b.jpg: 640x640 1 4, 4 5s, 239.5ms\n",
      "image 7/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-128-_jpg.rf.01caedc7c86d693ea337d14a6054129a.jpg: 640x640 2 4s, 2 5s, 219.1ms\n",
      "image 8/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-135-_jpg.rf.828c5cad3fcdba69655cd71621b953c3.jpg: 640x640 2 4s, 1 5, 221.4ms\n",
      "image 9/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-2-_jpg.rf.98ad04d69beacf3097a187ad77fa17fa.jpg: 640x640 2 0s, 1 5, 256.9ms\n",
      "image 10/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-24-_jpg.rf.4cef0ff39c6ec7ba06b3298680cc6b28.jpg: 640x640 1 0, 1 5, 222.7ms\n",
      "image 11/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-30-_jpg.rf.3e5ee15db4dfb8985c6d2f9aa159e436.jpg: 640x640 (no detections), 236.0ms\n",
      "image 12/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-31-_jpg.rf.097db28ac72fa2d268f48241987ff206.jpg: 640x640 2 0s, 2 5s, 223.5ms\n",
      "image 13/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-36-_jpg.rf.28455017f1359ec3d574e28ea916e701.jpg: 640x640 8 0s, 2 5s, 237.5ms\n",
      "image 14/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-46-_jpg.rf.8b40e60695629603d63df1888b47197f.jpg: 640x640 2 0s, 3 5s, 261.4ms\n",
      "image 15/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-50-_jpg.rf.9b814d0c40cddc47d0d027f5591d502f.jpg: 640x640 (no detections), 247.0ms\n",
      "image 16/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-56-_jpg.rf.0a6fcd77acb4d066adeac0bf29577ca2.jpg: 640x640 1 5, 248.0ms\n",
      "image 17/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-64-_jpg.rf.9af280aa66e985ea785f74b39110f3cb.jpg: 640x640 (no detections), 260.0ms\n",
      "image 18/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-68-_jpg.rf.b277cd334905e7d0e013e3421f9934fc.jpg: 640x640 5 0s, 2 5s, 242.3ms\n",
      "image 19/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-7-_jpg.rf.96fae53a9c0f4de217a0d291242759a9.jpg: 640x640 5 0s, 1 5, 233.9ms\n",
      "image 20/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-75-_jpg.rf.9f3eb21200832944140a89af96419630.jpg: 640x640 (no detections), 224.6ms\n",
      "image 21/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-78-_jpg.rf.04a0fcd99c99b1196a452662d6c6d5e1.jpg: 640x640 2 0s, 253.7ms\n",
      "image 22/22 c:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\test\\images\\B-8-_jpg.rf.3bfff7de7a35d6f72b9a82fb3ec02ae9.jpg: 640x640 6 0s, 1 5, 251.5ms\n",
      "Speed: 2.9ms preprocess, 234.8ms inference, 0.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection2-8s2\u001b[0m\n",
      "18 labels saved to runs\\detect\\detection2-8s2\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO8 2 датасет\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "_original_nms = torchvision.ops.nms\n",
    "torchvision.ops.nms = custom_nms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "# Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolov8s.pt')\n",
    "model.to(device)\n",
    "    \n",
    "# Обучение модели \n",
    "model.train(data='Yolo8v2/data.yaml', epochs=3, imgsz=640, batch=25, name='detection2-8s', device=device)\n",
    "      \n",
    "# Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Yolo8v2/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
