{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Лабораторная работа №4. Различные подходы к решению задачи детектирования объектов\n",
    "1. Загрузить набор данных «Номера тормозных башмаков» (data_sl.zip)\n",
    "2. Провести предварительный анализ набора данных, провести оценку качества набора данных, указать возможные пути улучшения набора данных\n",
    "3. Ознакомиться с материалами теории алгоритма фонтанного преобразования (например, https://newdisser.ru/_avtoreferats/01005395270.pdf, \n",
    "https://cyberleninka.ru/article/n/modelirovanie-protsessa-identifikatsii-graficheskihobektov/viewer)\n",
    "4. Разработать модуль распознавания номера башмака при помощи фонтанного преобразования\n",
    "5. Ознакомиться с материалами по архитектуре YOLOv11 (https://github.com/ultralytics/ultralytics, https://docs.ultralytics.com/quickstart/)\n",
    "6. Загрузить предобученную модель YOLOv11 для решения задачи распознавания цифр как подвида задачи детектирования объектов/сегментации изображений\n",
    "7. Разработать модуль распознавания номера башмака при помощи YOLOv11\n",
    "8. Провести сравнительный анализ эффективности методов фонтанного преобразования и модели на архитектуре YOLOv11 для решения задачи распознавания \n",
    "номера тормозного башмака.\n",
    "9. Сделать сравнительную таблицу с достоинствами, недостатками каждого алгоритма, особое внимание уделить точности и скорости работ\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 14.444%\n"
     ]
    }
   ],
   "source": [
    "#Фонтанное преобразование 1 датасет\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Путь к исполняемому файлу Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Tesseract\\tesseract.exe\"\n",
    "image_dir = 'Numbers_yolov11/train/images' # Путь к изображениям\n",
    "label_dir = 'Numbers_yolov11/train/labels' # Путь к меткам изображений\n",
    "\n",
    "def load_images_and_annotations(image_dir, label_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Загрузка изображения\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append((filename, img))\n",
    "            \n",
    "            # Загрузка аннотации\n",
    "            label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [line.strip().split() for line in f.readlines()]\n",
    "                annotations.append((filename, labels))\n",
    "            else:\n",
    "                annotations.append((filename, []))\n",
    "    return images, annotations\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразование в оттенки серого\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Инвертирование цветов\n",
    "    inverted = cv2.bitwise_not(gray)\n",
    "    # Применение адаптивной бинаризации\n",
    "    thresh = cv2.adaptiveThreshold(inverted, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def extract_digits(img):\n",
    "    # Настройка конфигурации Tesseract для распознавания только цифр\n",
    "    custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789'\n",
    "    result = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return result.strip()\n",
    "\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    average_precision = average_precision_score(true_labels, pred_labels, average='macro')\n",
    "    return precision, recall, average_precision\n",
    "\n",
    "#Загрузка изображений и меток\n",
    "images, annotations = load_images_and_annotations(image_dir, label_dir)\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "with open('results1.txt', 'w', encoding='utf-8') as f:\n",
    "    for (filename, img), (_, labels) in zip(images, annotations):\n",
    "        #print(f\"Файл: {filename}\")\n",
    "        # Предварительная обработка изображения\n",
    "        processed_img = preprocess_image(img)\n",
    "        # Извлечение предсказанных цифр\n",
    "        pred_digits = extract_digits(processed_img)\n",
    "        #print(f\"Распознанные метки: {pred_digits}\")\n",
    "        # Получение истинных меток из аннотаций\n",
    "        true_digits = [label[0] for label in labels]\n",
    "        #print(f\"Метки: {true_digits}\")\n",
    "        # Запись результатов в файл\n",
    "        # Формат: filename | распознанные метки | истинные метки\n",
    "        f.write(f\"Файл: {filename}\\n\")\n",
    "        f.write(f\"Распознанные метки: {''.join(pred_digits)}\\n\")\n",
    "        f.write(f\"Метки: {''.join(true_digits)}\\n\")\n",
    "        f.write(\"\\n\")  # разделитель между записями    \n",
    "\n",
    "        # Преобразование в бинарный формат для вычисления метрик\n",
    "        true_labels = [1 if str(i) in true_digits else 0 for i in range(10)]\n",
    "        pred_labels = [1 if str(i) in pred_digits else 0 for i in range(10)]       \n",
    "        all_true_labels.append(true_labels)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "\n",
    "\n",
    "# Вычисление точности\n",
    "precision = precision_score(all_true_labels, all_pred_labels, average='macro', zero_division=0) \n",
    "print(f\"Точность: {precision*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанные цифры: 7492\n",
      "404\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "def recognize_digits(image_path):\n",
    "    # Загружаем изображение\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Преобразуем изображение в оттенки серого\n",
    "    gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Применяем пороговое значение для улучшения контраста\n",
    "    _, thresh_image = cv2.threshold(gray_image, 150, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Распознаем текст (цифры) на изображении\n",
    "    custom_config = r'--oem 3 --psm 6 outputbase digits'\n",
    "    recognized_text = pytesseract.image_to_string(thresh_image, config=custom_config)\n",
    "\n",
    "    return recognized_text.strip()\n",
    "\n",
    "image_name = 'test1.jpg'\n",
    "result = recognize_digits(image_name)\n",
    "print(f'Распознанные цифры: {result}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распознанные цифры: 01234\n",
      "16789\n"
     ]
    }
   ],
   "source": [
    "image_name2 = 'test2.jpg'\n",
    "result2 = recognize_digits(image_name2)\n",
    "print(f'Распознанные цифры: {result2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 25.230%\n"
     ]
    }
   ],
   "source": [
    "#Фонтанное преобразование 2 датасет\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pytesseract\n",
    "import logging\n",
    "from sklearn.metrics import precision_score, recall_score, average_precision_score\n",
    "\n",
    "# Настройка логирования\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "# Путь к исполняемому файлу Tesseract\n",
    "pytesseract.pytesseract.tesseract_cmd = r\"C:\\Tesseract\\tesseract.exe\"\n",
    "image_dir = 'Yolo8v2/train/images' # Путь к изображениям\n",
    "label_dir = 'Yolo8v2/train/labels' # Путь к меткам изображений\n",
    "\n",
    "def load_images_and_annotations(image_dir, label_dir):\n",
    "    images = []\n",
    "    annotations = []\n",
    "    for filename in os.listdir(image_dir):\n",
    "        if filename.endswith((\".jpg\", \".png\")):\n",
    "            # Загрузка изображения\n",
    "            img_path = os.path.join(image_dir, filename)\n",
    "            img = cv2.imread(img_path)\n",
    "            images.append((filename, img))\n",
    "            \n",
    "            # Загрузка аннотации\n",
    "            label_filename = os.path.splitext(filename)[0] + \".txt\"\n",
    "            label_path = os.path.join(label_dir, label_filename)\n",
    "            if os.path.exists(label_path):\n",
    "                with open(label_path, 'r') as f:\n",
    "                    labels = [line.strip().split() for line in f.readlines()]\n",
    "                annotations.append((filename, labels))\n",
    "            else:\n",
    "                annotations.append((filename, []))\n",
    "    return images, annotations\n",
    "\n",
    "def preprocess_image(img):\n",
    "    # Преобразование в оттенки серого\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Инвертирование цветов\n",
    "    inverted = cv2.bitwise_not(gray)\n",
    "    # Применение адаптивной бинаризации\n",
    "    thresh = cv2.adaptiveThreshold(inverted, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY, 11, 2)\n",
    "    return thresh\n",
    "\n",
    "def extract_digits(img):\n",
    "    # Настройка конфигурации Tesseract для распознавания только цифр\n",
    "    custom_config = r'--oem 3 --psm 6 -c tessedit_char_whitelist=0123456789'\n",
    "    result = pytesseract.image_to_string(img, config=custom_config)\n",
    "    return result.strip()\n",
    "\n",
    "def calculate_metrics(true_labels, pred_labels):\n",
    "    precision = precision_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    recall = recall_score(true_labels, pred_labels, average='macro', zero_division=0)\n",
    "    average_precision = average_precision_score(true_labels, pred_labels, average='macro')\n",
    "    return precision, recall, average_precision\n",
    "\n",
    "#Загрузка изображений и меток\n",
    "images, annotations = load_images_and_annotations(image_dir, label_dir)\n",
    "all_true_labels = []\n",
    "all_pred_labels = []\n",
    "with open('results2.txt', 'w', encoding='utf-8') as f:\n",
    "    for (filename, img), (_, labels) in zip(images, annotations):\n",
    "        #print(f\"Файл: {filename}\")\n",
    "        # Предварительная обработка изображения\n",
    "        processed_img = preprocess_image(img)\n",
    "        # Извлечение предсказанных цифр\n",
    "        pred_digits = extract_digits(processed_img)\n",
    "        #print(f\"Распознанные метки: {pred_digits}\")\n",
    "        # Получение истинных меток из аннотаций\n",
    "        true_digits = [label[0] for label in labels]\n",
    "        #print(f\"Метки: {true_digits}\")\n",
    "        # Запись результатов в файл\n",
    "        # Формат: filename | распознанные метки | истинные метки\n",
    "        f.write(f\"Файл: {filename}\\n\")\n",
    "        f.write(f\"Распознанные метки: {''.join(pred_digits)}\\n\")\n",
    "        f.write(f\"Метки: {''.join(true_digits)}\\n\")\n",
    "        f.write(\"\\n\")  # разделитель между записями    \n",
    "\n",
    "        # Преобразование в бинарный формат для вычисления метрик\n",
    "        true_labels = [1 if str(i) in true_digits else 0 for i in range(10)]\n",
    "        pred_labels = [1 if str(i) in pred_digits else 0 for i in range(10)]       \n",
    "        all_true_labels.append(true_labels)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "\n",
    "\n",
    "# Вычисление точности\n",
    "precision = precision_score(all_true_labels, all_pred_labels, average='macro', zero_division=0) \n",
    "print(f\"Точность: {precision*100:.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Numbers_yolov11/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection2, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection2, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    432232  ultralytics.nn.modules.head.Detect           [8, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,591,400 parameters, 2,591,384 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.30.2 ms, read: 59.220.6 MB/s, size: 24.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov11\\train\\labels.cache... 97 images, 1 backgrounds, 0 corrupt: 100%|██████████| 97/97 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.1 ms, read: 55.014.9 MB/s, size: 23.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov11\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005859375000000001), 87 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection2\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.934      4.646      1.631        134        640: 100%|██████████| 4/4 [00:20<00:00,  5.16s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74          0          0          0          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G       1.68       4.56      1.464         87        640: 100%|██████████| 4/4 [00:19<00:00,  4.88s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74   0.000789     0.0102   0.000776   7.76e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.546      4.426      1.334        114        640: 100%|██████████| 4/4 [00:19<00:00,  4.81s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:02<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74    0.00178     0.0578    0.00125   0.000983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.019 hours.\n",
      "Optimizer stripped from runs\\detect\\detection2\\weights\\last.pt, 5.5MB\n",
      "Optimizer stripped from runs\\detect\\detection2\\weights\\best.pt, 5.5MB\n",
      "\n",
      "Validating runs\\detect\\detection2\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "YOLO11n summary (fused): 100 layers, 2,583,712 parameters, 0 gradients, 6.3 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74    0.00178     0.0578    0.00122   0.000963\n",
      "                     0         14         14     0.0115     0.0714    0.00757    0.00605\n",
      "                     1          4          4          0          0          0          0\n",
      "                     4         10         13          0          0          0          0\n",
      "                     5         17         28          0          0          0          0\n",
      "                     6          6          6   0.000974      0.333   0.000984   0.000689\n",
      "                     7          2          4          0          0          0          0\n",
      "                     8          5          5          0          0          0          0\n",
      "Speed: 1.1ms preprocess, 52.0ms inference, 0.0ms loss, 10.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection2\u001b[0m\n",
      "YOLO11n summary (fused): 100 layers, 2,583,712 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.00.0 ms, read: 364.363.0 MB/s, size: 25.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov11\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:01<00:00,  1.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74    0.00178     0.0578    0.00122   0.000963\n",
      "                     0         14         14     0.0115     0.0714    0.00757    0.00605\n",
      "                     1          4          4          0          0          0          0\n",
      "                     4         10         13          0          0          0          0\n",
      "                     5         17         28          0          0          0          0\n",
      "                     6          6          6   0.000974      0.333   0.000984   0.000689\n",
      "                     7          2          4          0          0          0          0\n",
      "                     8          5          5          0          0          0          0\n",
      "Speed: 3.4ms preprocess, 47.0ms inference, 0.0ms loss, 11.6ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection22\u001b[0m\n",
      "mAP для боксов: 0.000963297530517318\n",
      "\n",
      "image 1/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650106_jpg.rf.848e68240ae6864df221714f16ef0e97.jpg: 640x640 (no detections), 175.8ms\n",
      "image 2/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501101_jpg.rf.7a6800606789a61bcce0d56539c74f06.jpg: 640x640 (no detections), 97.5ms\n",
      "image 3/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501140_jpg.rf.9c17a64d40f589564c9c5063a7687209.jpg: 640x640 (no detections), 114.0ms\n",
      "image 4/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501180_jpg.rf.76e96c21ff790091132bdb4e9fd10f87.jpg: 640x640 (no detections), 137.8ms\n",
      "image 5/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501185_jpg.rf.dad6b6ed4d5acad105e7333a23dae357.jpg: 640x640 (no detections), 130.7ms\n",
      "image 6/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650119_jpg.rf.76d27479e4a19c2e6ff554af6812b1fc.jpg: 640x640 (no detections), 123.7ms\n",
      "image 7/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501284_jpg.rf.98f8ec758cec188b451d9ca2da4998d2.jpg: 640x640 (no detections), 122.0ms\n",
      "image 8/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501314_jpg.rf.b4d85baee790a4f125aff81e6f5df2d2.jpg: 640x640 (no detections), 135.9ms\n",
      "image 9/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_1426501315_jpg.rf.2eecb9c1bf1dde7a38fdc61cb15b39c5.jpg: 640x640 (no detections), 136.2ms\n",
      "image 10/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650360_jpg.rf.6c2784f868d7cf61e57292b58663719a.jpg: 640x640 (no detections), 142.9ms\n",
      "image 11/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_14265039_jpg.rf.a764b90158df06b18cecf408d8048593.jpg: 640x640 (no detections), 136.9ms\n",
      "image 12/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_14265045_jpg.rf.b1937d2593bd7757d811cd0303e98522.jpg: 640x640 (no detections), 125.7ms\n",
      "image 13/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650487_jpg.rf.06dff3c9266ce4ab893d090c625bf3cc.jpg: 640x640 (no detections), 113.8ms\n",
      "image 14/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650489_jpg.rf.50a27e2a4120b0013c7495dd53aac03b.jpg: 640x640 (no detections), 124.9ms\n",
      "image 15/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650528_jpg.rf.aae060939dd52b4e4e722ba3cde8d293.jpg: 640x640 (no detections), 120.1ms\n",
      "image 16/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650548_jpg.rf.4add2d80922c08a01ded690f2402b096.jpg: 640x640 (no detections), 123.6ms\n",
      "image 17/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650663_jpg.rf.023d2a900669e0230df1bc6e26d0d312.jpg: 640x640 (no detections), 131.1ms\n",
      "image 18/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650747_jpg.rf.2c7642d61ba0da23697abc5a3325591a.jpg: 640x640 (no detections), 120.3ms\n",
      "image 19/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650756_jpg.rf.e565ffb368b31a58be165875483e0e89.jpg: 640x640 (no detections), 106.0ms\n",
      "image 20/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650765_jpg.rf.755619bccfd1e172ecce0af948ddc670.jpg: 640x640 (no detections), 113.4ms\n",
      "image 21/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov11\\test\\images\\Video_2024-01-25_142650799_jpg.rf.1d9a8fc1cfa736c0bffd235ff46069d2.jpg: 640x640 (no detections), 131.0ms\n",
      "Speed: 3.4ms preprocess, 126.8ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection23\u001b[0m\n",
      "0 label saved to runs\\detect\\detection23\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO11 неудачно\n",
    "import os\n",
    "# Заставляем использовать python-реализацию NMS через переопределение\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Сохраняем оригинальную реализацию NMS, которая работает на CPU\n",
    "_original_nms = torchvision.ops.nms\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    # Переносим данные на CPU, выполняем NMS и возвращаем результат на исходном устройстве\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "# Переопределяем torchvision.ops.nms на нашу CPU-версию\n",
    "torchvision.ops.nms = custom_nms\n",
    "\n",
    "from ultralytics import YOLO\n",
    "\n",
    "\n",
    "# Определение устройства: 'cuda' для GPU, иначе 'cpu'\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # 1. Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolo11n.pt')\n",
    "model.to(device)  # Перевод модели на GPU, если доступен\n",
    "    \n",
    "    # 2. Обучение модели на GPU\n",
    "model.train(data='Numbers_yolov11/data.yaml', epochs=3, imgsz=640, batch=25, name='detection', device=device)\n",
    "    \n",
    "    # 3. Оценка модели на GPU\n",
    "metrics = model.val(device=device)\n",
    "print(f\"mAP для боксов: {metrics.box.map}\")\n",
    "    # print(f\"mAP для масок: {metrics.seg.map}\") - для сегментации, у меня ошибки выдаёт\n",
    "    \n",
    "    # 4. Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Numbers_yolov11/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Numbers_yolov8/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=3, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8725672  ultralytics.nn.modules.head.Detect           [8, [320, 640, 640]]          \n",
      "Model summary: 209 layers, 68,160,312 parameters, 68,160,296 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 296.5129.4 MB/s, size: 24.3 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\train\\labels... 97 images, 1 backgrounds, 0 corrupt: 100%|██████████| 97/97 [00:00<00:00, 1030.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.1 ms, read: 319.3133.9 MB/s, size: 23.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\valid\\labels... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<00:00, 958.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005859375000000001), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.922       5.05      1.755        134        640: 100%|██████████| 4/4 [12:59<00:00, 194.79s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:23<00:00, 23.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.878     0.0306     0.0395      0.025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.284      3.531      1.277         87        640: 100%|██████████| 4/4 [12:46<00:00, 191.59s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:23<00:00, 23.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.471      0.304      0.192      0.122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.225      2.864      1.234        114        640: 100%|██████████| 4/4 [12:22<00:00, 185.58s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:22<00:00, 22.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74       0.31      0.369      0.248      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.658 hours.\n",
      "Optimizer stripped from runs\\detect\\detection\\weights\\last.pt, 136.7MB\n",
      "Optimizer stripped from runs\\detect\\detection\\weights\\best.pt, 136.7MB\n",
      "\n",
      "Validating runs\\detect\\detection\\weights\\best.pt...\n",
      "Ultralytics 8.3.132  Python-3.11.9 torch-2.7.0+cpu CPU (12th Gen Intel Core(TM) i5-12450H)\n",
      "Model summary (fused): 112 layers, 68,131,272 parameters, 0 gradients, 257.4 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:21<00:00, 21.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.309      0.369      0.249      0.177\n",
      "                     0         14         14       0.23      0.929      0.516      0.397\n",
      "                     1          4          4     0.0372       0.75       0.52      0.388\n",
      "                     4         10         13     0.0816      0.154     0.0727     0.0413\n",
      "                     5         17         28      0.499       0.25      0.351      0.226\n",
      "                     6          6          6      0.313        0.5      0.265      0.179\n",
      "                     7          2          4          1          0    0.00223    0.00178\n",
      "                     8          5          5          0          0     0.0152      0.008\n",
      "Speed: 1.9ms preprocess, 877.7ms inference, 0.0ms loss, 32.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection\u001b[0m\n",
      "Model summary (fused): 112 layers, 68,131,272 parameters, 0 gradients, 257.4 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.20.2 ms, read: 274.886.5 MB/s, size: 25.7 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Numbers_yolov8\\valid\\labels.cache... 23 images, 0 backgrounds, 0 corrupt: 100%|██████████| 23/23 [00:00<?, ?it/s]\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 1/1 [00:20<00:00, 20.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         23         74      0.309      0.369      0.249      0.177\n",
      "                     0         14         14       0.23      0.929      0.516      0.397\n",
      "                     1          4          4     0.0372       0.75       0.52      0.388\n",
      "                     4         10         13     0.0816      0.154     0.0727     0.0413\n",
      "                     5         17         28      0.499       0.25      0.351      0.226\n",
      "                     6          6          6      0.313        0.5      0.265      0.179\n",
      "                     7          2          4          1          0    0.00223    0.00178\n",
      "                     8          5          5          0          0     0.0152      0.008\n",
      "Speed: 1.3ms preprocess, 861.7ms inference, 0.0ms loss, 29.4ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\detection2\u001b[0m\n",
      "mAP для боксов: 0.17722197884440807\n",
      "\n",
      "image 1/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650106_jpg.rf.848e68240ae6864df221714f16ef0e97.jpg: 640x640 1 0, 912.0ms\n",
      "image 2/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501101_jpg.rf.7a6800606789a61bcce0d56539c74f06.jpg: 640x640 (no detections), 838.8ms\n",
      "image 3/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501140_jpg.rf.9c17a64d40f589564c9c5063a7687209.jpg: 640x640 (no detections), 811.3ms\n",
      "image 4/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501180_jpg.rf.76e96c21ff790091132bdb4e9fd10f87.jpg: 640x640 (no detections), 820.0ms\n",
      "image 5/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501185_jpg.rf.dad6b6ed4d5acad105e7333a23dae357.jpg: 640x640 (no detections), 805.1ms\n",
      "image 6/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650119_jpg.rf.76d27479e4a19c2e6ff554af6812b1fc.jpg: 640x640 1 0, 799.6ms\n",
      "image 7/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501284_jpg.rf.98f8ec758cec188b451d9ca2da4998d2.jpg: 640x640 (no detections), 814.9ms\n",
      "image 8/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501314_jpg.rf.b4d85baee790a4f125aff81e6f5df2d2.jpg: 640x640 (no detections), 780.9ms\n",
      "image 9/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_1426501315_jpg.rf.2eecb9c1bf1dde7a38fdc61cb15b39c5.jpg: 640x640 (no detections), 749.4ms\n",
      "image 10/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650360_jpg.rf.6c2784f868d7cf61e57292b58663719a.jpg: 640x640 3 0s, 822.1ms\n",
      "image 11/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265039_jpg.rf.a764b90158df06b18cecf408d8048593.jpg: 640x640 3 0s, 1 1, 816.6ms\n",
      "image 12/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_14265045_jpg.rf.b1937d2593bd7757d811cd0303e98522.jpg: 640x640 2 0s, 798.3ms\n",
      "image 13/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650487_jpg.rf.06dff3c9266ce4ab893d090c625bf3cc.jpg: 640x640 (no detections), 797.6ms\n",
      "image 14/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650489_jpg.rf.50a27e2a4120b0013c7495dd53aac03b.jpg: 640x640 1 0, 796.2ms\n",
      "image 15/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650528_jpg.rf.aae060939dd52b4e4e722ba3cde8d293.jpg: 640x640 (no detections), 836.9ms\n",
      "image 16/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650548_jpg.rf.4add2d80922c08a01ded690f2402b096.jpg: 640x640 2 0s, 802.7ms\n",
      "image 17/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650663_jpg.rf.023d2a900669e0230df1bc6e26d0d312.jpg: 640x640 (no detections), 809.0ms\n",
      "image 18/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650747_jpg.rf.2c7642d61ba0da23697abc5a3325591a.jpg: 640x640 (no detections), 816.4ms\n",
      "image 19/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650756_jpg.rf.e565ffb368b31a58be165875483e0e89.jpg: 640x640 2 0s, 814.3ms\n",
      "image 20/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650765_jpg.rf.755619bccfd1e172ecce0af948ddc670.jpg: 640x640 3 0s, 774.9ms\n",
      "image 21/21 c:\\PNRPU\\PNRPU\\    \\ 4\\Numbers_yolov8\\test\\images\\Video_2024-01-25_142650799_jpg.rf.1d9a8fc1cfa736c0bffd235ff46069d2.jpg: 640x640 (no detections), 783.7ms\n",
      "Speed: 2.8ms preprocess, 809.6ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\detection3\u001b[0m\n",
      "9 labels saved to runs\\detect\\detection3\\labels\n"
     ]
    }
   ],
   "source": [
    "# YOLO8 1 датасет\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "_original_nms = torchvision.ops.nms\n",
    "torchvision.ops.nms = custom_nms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "# Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolov8x.pt')\n",
    "model.to(device)\n",
    "    \n",
    "# Обучение модели \n",
    "model.train(data='Numbers_yolov8/data.yaml', epochs=3, imgsz=640, batch=25, name='detection', device=device)\n",
    "      \n",
    "# Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Numbers_yolov8/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=25, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=Yolo8v2/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=2, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=detection5, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=None, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=runs\\detect\\detection5, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=8\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n",
      "  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n",
      "  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n",
      "  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n",
      "  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n",
      "  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n",
      "  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n",
      "  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      "  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n",
      "  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n",
      " 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n",
      " 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n",
      " 22        [15, 18, 21]  1   8725672  ultralytics.nn.modules.head.Detect           [8, [320, 640, 640]]          \n",
      "Model summary: 209 layers, 68,160,312 parameters, 68,160,296 gradients, 258.2 GFLOPs\n",
      "\n",
      "Transferred 589/595 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 389.3113.2 MB/s, size: 28.1 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\train\\labels... 309 images, 6 backgrounds, 0 corrupt: 100%|██████████| 309/309 [00:00<00:00, 1683.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\train\\labels.cache\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 0.10.0 ms, read: 319.995.1 MB/s, size: 19.6 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\PNRPU\\PNRPU\\Модели и технологии машинного обучения\\Лабораторная 4\\Yolo8v2\\valid\\labels... 22 images, 0 backgrounds, 0 corrupt: 100%|██████████| 22/22 [00:00<00:00, 1983.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\PNRPU\\PNRPU\\    \\ 4\\Yolo8v2\\valid\\labels.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\sergei\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\detection5\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000833, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005859375000000001), 103 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\detection5\u001b[0m\n",
      "Starting training for 2 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/2         0G      2.749      4.411      2.799        150        640:  54%|█████▍    | 7/13 [21:42<18:45, 187.60s/it]"
     ]
    }
   ],
   "source": [
    "# YOLO8 2 датасет\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from ultralytics import YOLO\n",
    "\n",
    "def custom_nms(boxes, scores, iou_threshold):\n",
    "    boxes_cpu = boxes.cpu()\n",
    "    scores_cpu = scores.cpu()\n",
    "    keep = _original_nms(boxes_cpu, scores_cpu, iou_threshold)\n",
    "    return keep.to(boxes.device)\n",
    "\n",
    "os.environ[\"TORCHVISION_NMS_IMPL\"] = \"python\"\n",
    "_original_nms = torchvision.ops.nms\n",
    "torchvision.ops.nms = custom_nms\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "# Загрузка предварительно обученной модели YOLO (yolov8x.pt)\n",
    "model = YOLO('yolov8x.pt')\n",
    "model.to(device)\n",
    "    \n",
    "# Обучение модели \n",
    "model.train(data='Yolo8v2/data.yaml', epochs=2, imgsz=640, batch=25, name='detection', device=device)\n",
    "      \n",
    "# Использование модели для предсказания на тестовых изображениях с использованием GPU\n",
    "results = model.predict(source='Yolo8v2/test/images', save=True, save_txt=True, save_conf=True, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
